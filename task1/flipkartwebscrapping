import requests
from bs4 import BeautifulSoup as bs
import pandas as pd

# Flipkart URL for a specific product category
url = "https://www.flipkart.com/search?q=mobiles"

# Add headers to mimic a real browser request
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.5",
}

# Send the GET request with the headers
response = requests.get(url, headers=headers)

# Check if the page was retrieved successfully
if response.status_code == 200:
    # Parse the page content with BeautifulSoup
    soup = bs(response.content, 'html.parser')

    # Debugging: Print the page content to check if it's loaded correctly
    print(soup.prettify())  # Print the entire HTML for inspection

    # Create empty lists to store product details
    product_names = []
    prices = []
    image_urls = []

    # Find all elements containing product details
    product_containers = soup.find_all("div", class_="_1AtVbE")  # You may need to refine this

    # Loop through each product container to extract details
    for container in product_containers:
        # Extract the product name
        name_block = container.find("a", class_="IRpwTa")  # Update this class name if needed
        if name_block:
            name = name_block.text.strip()
        else:
            name = None

        # Extract the price
        price_block = container.find("div", class_="_30jeq3")  # Update this class name if needed
        if price_block:
            price = price_block.text.strip()
        else:
            price = None

        # Extract the image URL
        img_block = container.find("img", class_="DByuf4")  # Update this class name if needed
        if img_block:
            img_url = img_block['src']
        else:
            img_url = None

        # Add the details to the lists if all are found
        if name and price and img_url:
            product_names.append(name)
            prices.append(price)
            image_urls.append(img_url)

    # Create a DataFrame to store the results
    df = pd.DataFrame({
        'Product Name': product_names,
        'Price': prices,
        'Image URL': image_urls
    })

    # Display the DataFrame
    print(df)

    # Save the data to a CSV file
    df.to_csv('flipkart_products.csv', index=False, encoding='utf-8')
    print('Data saved to flipkart_products.csv')
    
else:
    print(f"Failed to retrieve page. Status code: {response.status_code}")
